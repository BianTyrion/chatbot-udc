[General]
globstep = 45000
corpus = ubuntu

[Dataset]
datasettag = round3_7
maxlength = 50
filtervocab = 1
skiplines = False
vocabularysize = 10000

[Network]
hiddensize = 256
numlayers = 2
initembeddings = False
embeddingsize = 256
embeddingsource = GoogleNews-vectors-negative300.bin

[Training (won't be restored)]
learningrate = 0.002
batchsize = 32
dropout = 0.9

